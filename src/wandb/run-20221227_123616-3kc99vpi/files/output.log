Found 27000 files belonging to 10 classes.
Using 21600 files for training.
2022-12-27 12:36:18.524428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:18.790213: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:18.790307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:18.793238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-27 12:36:18.794337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:18.794405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:18.794448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:19.885139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:19.886501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:19.886556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1041] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2022-12-27 12:36:19.886611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1614] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21635 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6
2022-12-27 12:36:20.955077: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [21600]
	 [[{{node Placeholder/_0}}]]
2022-12-27 12:36:20.955262: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [21600]
	 [[{{node Placeholder/_4}}]]
2022-12-27 12:36:21.518229: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [21600]
	 [[{{node Placeholder/_4}}]]
2022-12-27 12:36:21.518406: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [21600]
	 [[{{node Placeholder/_4}}]]
Found 27000 files belonging to 10 classes.
Using 5400 files for validation.
['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']
(32, 180, 180, 3)
(32,)
Model: "my-model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_1 (InputLayer)        [(None, 180, 180, 3)]     0
 conv2d (Conv2D)             (None, 180, 180, 128)     3584
 conv2d_1 (Conv2D)           (None, 180, 180, 128)     147584
 conv2d_2 (Conv2D)           (None, 90, 90, 128)       147584
 conv2d_3 (Conv2D)           (None, 90, 90, 64)        73792
 conv2d_4 (Conv2D)           (None, 90, 90, 64)        36928
 conv2d_5 (Conv2D)           (None, 45, 45, 64)        36928
 conv2d_6 (Conv2D)           (None, 45, 45, 32)        18464
 conv2d_7 (Conv2D)           (None, 45, 45, 32)        9248
 conv2d_8 (Conv2D)           (None, 45, 45, 32)        9248
 conv2d_9 (Conv2D)           (None, 23, 23, 32)        9248
 conv2d_10 (Conv2D)          (None, 23, 23, 16)        4624
 conv2d_11 (Conv2D)          (None, 23, 23, 16)        2320
 conv2d_12 (Conv2D)          (None, 23, 23, 16)        2320
 conv2d_13 (Conv2D)          (None, 12, 12, 16)        2320
 conv2d_14 (Conv2D)          (None, 12, 12, 8)         1160
 conv2d_15 (Conv2D)          (None, 12, 12, 8)         584
 conv2d_16 (Conv2D)          (None, 12, 12, 8)         584
 flatten (Flatten)           (None, 1152)              0
 dense (Dense)               (None, 10)                11530
=================================================================
Total params: 518,050
Trainable params: 518,050
Non-trainable params: 0
_________________________________________________________________
2022-12-27 12:36:21.995092: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [5400]
	 [[{{node Placeholder/_4}}]]
2022-12-27 12:36:21.995266: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [5400]
	 [[{{node Placeholder/_4}}]]
[34m[1mwandb[39m[22m: [33mWARNING[39m When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.
2022-12-27 12:36:22.808031: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [21600]
	 [[{{node Placeholder/_4}}]]
2022-12-27 12:36:22.808200: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [21600]
	 [[{{node Placeholder/_0}}]]
Epoch 1/4
2022-12-27 12:36:25.627057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700
2022-12-27 12:36:27.131835: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-12-27 12:36:27.659367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2022-12-27 12:36:27.697794: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f16c4502610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-27 12:36:27.697807: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2022-12-27 12:36:27.729406: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-27 12:36:27.969347: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-12-27 12:36:28.025867: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  6/675 [..............................] - ETA: 59s - loss: 45.8873 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: 45.8873WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0311s vs `on_train_batch_end` time: 0.0483s). Check your callbacks.





























675/675 [==============================] - ETA: 0s - loss: 10.6813 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: 10.6813

675/675 [==============================] - ETA: 0s - loss: 10.6813 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: 10.6813INFO:tensorflow:Assets written to: models/assets
INFO:tensorflow:Assets written to: models/assets
[34m[1mwandb[39m[22m: Adding directory to artifact (./models)... Done. 0.0s
675/675 [==============================] - 79s 100ms/step - loss: 10.6813 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: 10.6813 - val_loss: -28.6054 - val_categorical_accuracy: 0.0000e+00 - val_binary_crossentropy: -28.6054
Epoch 2/4




























675/675 [==============================] - ETA: 0s - loss: -28.0240 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.0240INFO:tensorflow:Assets written to: models/assets
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: models/assets
[34m[1mwandb[39m[22m: Adding directory to artifact (./models)... Done. 0.0s
675/675 [==============================] - 64s 95ms/step - loss: -28.0240 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.0240 - val_loss: -28.6054 - val_categorical_accuracy: 0.0000e+00 - val_binary_crossentropy: -28.6054
Epoch 3/4




























675/675 [==============================] - ETA: 0s - loss: -28.0240 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.0240
675/675 [==============================] - 64s 95ms/step - loss: -28.0240 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.0240 - val_loss: -28.6054 - val_categorical_accuracy: 0.0000e+00 - val_binary_crossentropy: -28.6054
Epoch 4/4





























675/675 [==============================] - ETA: 0s - loss: -28.0240 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.0240
675/675 [==============================] - 65s 96ms/step - loss: -28.0240 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.0240 - val_loss: -28.6026 - val_categorical_accuracy: 0.0000e+00 - val_binary_crossentropy: -28.6026


169/169 [==============================] - 6s 38ms/step - loss: -28.6026 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.6026
[-28.60259246826172, 0.0, -28.60259246826172]
Epoch 1/4
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0305s vs `on_train_batch_end` time: 0.0441s). Check your callbacks.
  6/675 [..............................] - ETA: 55s - loss: -25.0652 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -25.0652WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0305s vs `on_train_batch_end` time: 0.0441s). Check your callbacks.



 60/675 [=>............................] - ETA: 50s - loss: -28.1774 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.1774Epoch 1/4
  6/675 [..............................] - ETA: 1:00 - loss: -24.5905 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -24.5905WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0317s vs `on_train_batch_end` time: 0.0490s). Check your callbacks.
  8/675 [..............................] - ETA: 1:00 - loss: -24.4006 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -24.4006


 40/675 [>.............................] - ETA: 57s - loss: -28.5591 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -28.5591Model: "my-model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_2 (InputLayer)        [(None, 180, 180, 3)]     0
 conv2d_17 (Conv2D)          (None, 180, 180, 128)     3584
 re_lu (ReLU)                (None, 180, 180, 128)     0
 conv2d_18 (Conv2D)          (None, 180, 180, 128)     147584
 re_lu_1 (ReLU)              (None, 180, 180, 128)     0
 conv2d_19 (Conv2D)          (None, 90, 90, 128)       147584
 conv2d_20 (Conv2D)          (None, 90, 90, 64)        73792
 re_lu_2 (ReLU)              (None, 90, 90, 64)        0
 conv2d_21 (Conv2D)          (None, 90, 90, 64)        36928
 re_lu_3 (ReLU)              (None, 90, 90, 64)        0
 conv2d_22 (Conv2D)          (None, 45, 45, 64)        36928
 conv2d_23 (Conv2D)          (None, 45, 45, 32)        18464
 re_lu_4 (ReLU)              (None, 45, 45, 32)        0
 conv2d_24 (Conv2D)          (None, 45, 45, 32)        9248
 re_lu_5 (ReLU)              (None, 45, 45, 32)        0
 conv2d_25 (Conv2D)          (None, 45, 45, 32)        9248
 re_lu_6 (ReLU)              (None, 45, 45, 32)        0
 conv2d_26 (Conv2D)          (None, 23, 23, 32)        9248
 conv2d_27 (Conv2D)          (None, 23, 23, 16)        4624
 re_lu_7 (ReLU)              (None, 23, 23, 16)        0
 conv2d_28 (Conv2D)          (None, 23, 23, 16)        2320
 re_lu_8 (ReLU)              (None, 23, 23, 16)        0
 conv2d_29 (Conv2D)          (None, 23, 23, 16)        2320
 re_lu_9 (ReLU)              (None, 23, 23, 16)        0
 conv2d_30 (Conv2D)          (None, 12, 12, 16)        2320
 conv2d_31 (Conv2D)          (None, 12, 12, 8)         1160
 re_lu_10 (ReLU)             (None, 12, 12, 8)         0
 conv2d_32 (Conv2D)          (None, 12, 12, 8)         584
 re_lu_11 (ReLU)             (None, 12, 12, 8)         0
 conv2d_33 (Conv2D)          (None, 12, 12, 8)         584
 re_lu_12 (ReLU)             (None, 12, 12, 8)         0
 flatten_1 (Flatten)         (None, 1152)              0
 dense_1 (Dense)             (None, 10)                11530
=================================================================
Total params: 518,050
Trainable params: 518,050
Non-trainable params: 0
_________________________________________________________________
Epoch 1/4
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0352s vs `on_train_batch_end` time: 0.0565s). Check your callbacks.
  6/675 [..............................] - ETA: 1:08 - loss: 12.5307 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: 12.5307WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0352s vs `on_train_batch_end` time: 0.0565s). Check your callbacks.



 70/675 [==>...........................] - ETA: 56s - loss: -13.7863 - categorical_accuracy: 0.0000e+00 - binary_crossentropy: -13.7863Model: "my-model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_3 (InputLayer)           [(None, 180, 180, 3  0           []
                                )]
 conv2d_34 (Conv2D)             (None, 180, 180, 12  3584        ['input_3[0][0]']
                                8)
 re_lu_13 (ReLU)                (None, 180, 180, 12  0           ['conv2d_34[0][0]']
                                8)
 conv2d_35 (Conv2D)             (None, 180, 180, 12  147584      ['re_lu_13[0][0]']
                                8)
 re_lu_14 (ReLU)                (None, 180, 180, 12  0           ['conv2d_35[0][0]']
                                8)
 conv2d_36 (Conv2D)             (None, 180, 180, 12  147584      ['re_lu_14[0][0]']
                                8)
 batch_normalization (BatchNorm  (None, 180, 180, 12  512        ['conv2d_36[0][0]']
 alization)                     8)
 conv2d_37 (Conv2D)             (None, 180, 180, 12  147584      ['batch_normalization[0][0]']
                                8)
 add (Add)                      (None, 180, 180, 12  0           ['re_lu_14[0][0]',
                                8)                                'conv2d_37[0][0]']
 re_lu_15 (ReLU)                (None, 180, 180, 12  0           ['add[0][0]']
                                8)
 batch_normalization_1 (BatchNo  (None, 180, 180, 12  512        ['re_lu_15[0][0]']
 rmalization)                   8)
 conv2d_38 (Conv2D)             (None, 90, 90, 128)  147584      ['batch_normalization_1[0][0]']
 conv2d_39 (Conv2D)             (None, 90, 90, 64)   73792       ['conv2d_38[0][0]']
 re_lu_16 (ReLU)                (None, 90, 90, 64)   0           ['conv2d_39[0][0]']
 conv2d_40 (Conv2D)             (None, 90, 90, 64)   36928       ['re_lu_16[0][0]']
 re_lu_17 (ReLU)                (None, 90, 90, 64)   0           ['conv2d_40[0][0]']
 conv2d_41 (Conv2D)             (None, 90, 90, 64)   36928       ['re_lu_17[0][0]']
 batch_normalization_2 (BatchNo  (None, 90, 90, 64)  256         ['conv2d_41[0][0]']
 rmalization)
 conv2d_42 (Conv2D)             (None, 90, 90, 64)   36928       ['batch_normalization_2[0][0]']
 add_1 (Add)                    (None, 90, 90, 64)   0           ['re_lu_17[0][0]',
                                                                  'conv2d_42[0][0]']
 re_lu_18 (ReLU)                (None, 90, 90, 64)   0           ['add_1[0][0]']
 batch_normalization_3 (BatchNo  (None, 90, 90, 64)  256         ['re_lu_18[0][0]']
 rmalization)
 conv2d_43 (Conv2D)             (None, 45, 45, 64)   36928       ['batch_normalization_3[0][0]']
 conv2d_44 (Conv2D)             (None, 45, 45, 32)   18464       ['conv2d_43[0][0]']
 re_lu_19 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_44[0][0]']
 conv2d_45 (Conv2D)             (None, 45, 45, 32)   9248        ['re_lu_19[0][0]']
 re_lu_20 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_45[0][0]']
 conv2d_46 (Conv2D)             (None, 45, 45, 32)   9248        ['re_lu_20[0][0]']
 re_lu_21 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_46[0][0]']
 conv2d_47 (Conv2D)             (None, 45, 45, 32)   9248        ['re_lu_21[0][0]']
 batch_normalization_4 (BatchNo  (None, 45, 45, 32)  128         ['conv2d_47[0][0]']
 rmalization)
 conv2d_48 (Conv2D)             (None, 45, 45, 32)   9248        ['batch_normalization_4[0][0]']
 add_2 (Add)                    (None, 45, 45, 32)   0           ['re_lu_21[0][0]',
                                                                  'conv2d_48[0][0]']
 re_lu_22 (ReLU)                (None, 45, 45, 32)   0           ['add_2[0][0]']
 batch_normalization_5 (BatchNo  (None, 45, 45, 32)  128         ['re_lu_22[0][0]']
 rmalization)
 conv2d_49 (Conv2D)             (None, 23, 23, 32)   9248        ['batch_normalization_5[0][0]']
 conv2d_50 (Conv2D)             (None, 23, 23, 16)   4624        ['conv2d_49[0][0]']
 re_lu_23 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_50[0][0]']
 conv2d_51 (Conv2D)             (None, 23, 23, 16)   2320        ['re_lu_23[0][0]']
 re_lu_24 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_51[0][0]']
 conv2d_52 (Conv2D)             (None, 23, 23, 16)   2320        ['re_lu_24[0][0]']
 re_lu_25 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_52[0][0]']
 conv2d_53 (Conv2D)             (None, 23, 23, 16)   2320        ['re_lu_25[0][0]']
 batch_normalization_6 (BatchNo  (None, 23, 23, 16)  64          ['conv2d_53[0][0]']
 rmalization)
 conv2d_54 (Conv2D)             (None, 23, 23, 16)   2320        ['batch_normalization_6[0][0]']
 add_3 (Add)                    (None, 23, 23, 16)   0           ['re_lu_25[0][0]',
                                                                  'conv2d_54[0][0]']
 re_lu_26 (ReLU)                (None, 23, 23, 16)   0           ['add_3[0][0]']
 batch_normalization_7 (BatchNo  (None, 23, 23, 16)  64          ['re_lu_26[0][0]']
 rmalization)
 conv2d_55 (Conv2D)             (None, 12, 12, 16)   2320        ['batch_normalization_7[0][0]']
 conv2d_56 (Conv2D)             (None, 12, 12, 8)    1160        ['conv2d_55[0][0]']
 re_lu_27 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_56[0][0]']
 conv2d_57 (Conv2D)             (None, 12, 12, 8)    584         ['re_lu_27[0][0]']
 re_lu_28 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_57[0][0]']
 conv2d_58 (Conv2D)             (None, 12, 12, 8)    584         ['re_lu_28[0][0]']
 re_lu_29 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_58[0][0]']
 conv2d_59 (Conv2D)             (None, 12, 12, 8)    584         ['re_lu_29[0][0]']
 batch_normalization_8 (BatchNo  (None, 12, 12, 8)   32          ['conv2d_59[0][0]']
 rmalization)
 conv2d_60 (Conv2D)             (None, 12, 12, 8)    584         ['batch_normalization_8[0][0]']
 add_4 (Add)                    (None, 12, 12, 8)    0           ['re_lu_29[0][0]',
                                                                  'conv2d_60[0][0]']
 re_lu_30 (ReLU)                (None, 12, 12, 8)    0           ['add_4[0][0]']
 batch_normalization_9 (BatchNo  (None, 12, 12, 8)   32          ['re_lu_30[0][0]']
 rmalization)
 flatten_2 (Flatten)            (None, 1152)         0           ['batch_normalization_9[0][0]']
 dense_2 (Dense)                (None, 10)           11530       ['flatten_2[0][0]']
==================================================================================================
Total params: 913,362
Trainable params: 912,370
Non-trainable params: 992
__________________________________________________________________________________________________
Epoch 1/4
  2/675 [..............................] - ETA: 2:22 - loss: 14.9986 - categorical_accuracy: 0.1875 - binary_crossentropy: 14.9986
  6/675 [..............................] - ETA: 2:17 - loss: 0.4428 - categorical_accuracy: 0.1146 - binary_crossentropy: 0.4428WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0721s vs `on_train_batch_end` time: 0.1106s). Check your callbacks.


 20/675 [..............................] - ETA: 2:11 - loss: -30.9146 - categorical_accuracy: 0.0922 - binary_crossentropy: -30.9146Epoch 1/4
Model: "my-model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_4 (InputLayer)           [(None, 180, 180, 3  0           []
                                )]
 conv2d_61 (Conv2D)             (None, 180, 180, 12  3584        ['input_4[0][0]']
                                8)
 re_lu_31 (ReLU)                (None, 180, 180, 12  0           ['conv2d_61[0][0]']
                                8)
 conv2d_62 (Conv2D)             (None, 180, 180, 12  147584      ['re_lu_31[0][0]']
                                8)
 re_lu_32 (ReLU)                (None, 180, 180, 12  0           ['conv2d_62[0][0]']
                                8)
 conv2d_63 (Conv2D)             (None, 180, 180, 12  147584      ['re_lu_32[0][0]']
                                8)
 batch_normalization_10 (BatchN  (None, 180, 180, 12  512        ['conv2d_63[0][0]']
 ormalization)                  8)
 conv2d_64 (Conv2D)             (None, 180, 180, 12  147584      ['batch_normalization_10[0][0]']
                                8)
 add_5 (Add)                    (None, 180, 180, 12  0           ['re_lu_32[0][0]',
                                8)                                'conv2d_64[0][0]']
 re_lu_33 (ReLU)                (None, 180, 180, 12  0           ['add_5[0][0]']
                                8)
 batch_normalization_11 (BatchN  (None, 180, 180, 12  512        ['re_lu_33[0][0]']
 ormalization)                  8)
 conv2d_65 (Conv2D)             (None, 90, 90, 128)  147584      ['batch_normalization_11[0][0]']
 conv2d_66 (Conv2D)             (None, 90, 90, 64)   73792       ['conv2d_65[0][0]']
 re_lu_34 (ReLU)                (None, 90, 90, 64)   0           ['conv2d_66[0][0]']
 conv2d_67 (Conv2D)             (None, 90, 90, 64)   36928       ['re_lu_34[0][0]']
 re_lu_35 (ReLU)                (None, 90, 90, 64)   0           ['conv2d_67[0][0]']
 conv2d_68 (Conv2D)             (None, 90, 90, 64)   36928       ['re_lu_35[0][0]']
 batch_normalization_12 (BatchN  (None, 90, 90, 64)  256         ['conv2d_68[0][0]']
 ormalization)
 conv2d_69 (Conv2D)             (None, 90, 90, 64)   36928       ['batch_normalization_12[0][0]']
 add_6 (Add)                    (None, 90, 90, 64)   0           ['re_lu_35[0][0]',
                                                                  'conv2d_69[0][0]']
 re_lu_36 (ReLU)                (None, 90, 90, 64)   0           ['add_6[0][0]']
 batch_normalization_13 (BatchN  (None, 90, 90, 64)  256         ['re_lu_36[0][0]']
 ormalization)
 conv2d_70 (Conv2D)             (None, 45, 45, 64)   36928       ['batch_normalization_13[0][0]']
 conv2d_71 (Conv2D)             (None, 45, 45, 32)   18464       ['conv2d_70[0][0]']
 re_lu_37 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_71[0][0]']
 conv2d_72 (Conv2D)             (None, 45, 45, 32)   9248        ['re_lu_37[0][0]']
 re_lu_38 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_72[0][0]']
 conv2d_73 (Conv2D)             (None, 45, 45, 32)   9248        ['re_lu_38[0][0]']
 re_lu_39 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_73[0][0]']
 conv2d_74 (Conv2D)             (None, 45, 45, 32)   9248        ['re_lu_39[0][0]']
 batch_normalization_14 (BatchN  (None, 45, 45, 32)  128         ['conv2d_74[0][0]']
 ormalization)
 conv2d_75 (Conv2D)             (None, 45, 45, 32)   9248        ['batch_normalization_14[0][0]']
 add_7 (Add)                    (None, 45, 45, 32)   0           ['re_lu_39[0][0]',
                                                                  'conv2d_75[0][0]']
 re_lu_40 (ReLU)                (None, 45, 45, 32)   0           ['add_7[0][0]']
 batch_normalization_15 (BatchN  (None, 45, 45, 32)  128         ['re_lu_40[0][0]']
 ormalization)
 conv2d_76 (Conv2D)             (None, 23, 23, 32)   9248        ['batch_normalization_15[0][0]']
 conv2d_77 (Conv2D)             (None, 23, 23, 16)   4624        ['conv2d_76[0][0]']
 re_lu_41 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_77[0][0]']
 conv2d_78 (Conv2D)             (None, 23, 23, 16)   2320        ['re_lu_41[0][0]']
 re_lu_42 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_78[0][0]']
 conv2d_79 (Conv2D)             (None, 23, 23, 16)   2320        ['re_lu_42[0][0]']
 re_lu_43 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_79[0][0]']
 conv2d_80 (Conv2D)             (None, 23, 23, 16)   2320        ['re_lu_43[0][0]']
 batch_normalization_16 (BatchN  (None, 23, 23, 16)  64          ['conv2d_80[0][0]']
 ormalization)
 conv2d_81 (Conv2D)             (None, 23, 23, 16)   2320        ['batch_normalization_16[0][0]']
 add_8 (Add)                    (None, 23, 23, 16)   0           ['re_lu_43[0][0]',
                                                                  'conv2d_81[0][0]']
 re_lu_44 (ReLU)                (None, 23, 23, 16)   0           ['add_8[0][0]']
 batch_normalization_17 (BatchN  (None, 23, 23, 16)  64          ['re_lu_44[0][0]']
 ormalization)
 conv2d_82 (Conv2D)             (None, 12, 12, 16)   2320        ['batch_normalization_17[0][0]']
 conv2d_83 (Conv2D)             (None, 12, 12, 8)    1160        ['conv2d_82[0][0]']
 re_lu_45 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_83[0][0]']
 conv2d_84 (Conv2D)             (None, 12, 12, 8)    584         ['re_lu_45[0][0]']
 re_lu_46 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_84[0][0]']
 conv2d_85 (Conv2D)             (None, 12, 12, 8)    584         ['re_lu_46[0][0]']
 re_lu_47 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_85[0][0]']
 conv2d_86 (Conv2D)             (None, 12, 12, 8)    584         ['re_lu_47[0][0]']
 batch_normalization_18 (BatchN  (None, 12, 12, 8)   32          ['conv2d_86[0][0]']
 ormalization)
 conv2d_87 (Conv2D)             (None, 12, 12, 8)    584         ['batch_normalization_18[0][0]']
 add_9 (Add)                    (None, 12, 12, 8)    0           ['re_lu_47[0][0]',
                                                                  'conv2d_87[0][0]']
 re_lu_48 (ReLU)                (None, 12, 12, 8)    0           ['add_9[0][0]']
 batch_normalization_19 (BatchN  (None, 12, 12, 8)   32          ['re_lu_48[0][0]']
 ormalization)
 flatten_3 (Flatten)            (None, 1152)         0           ['batch_normalization_19[0][0]']
 dense_3 (Dense)                (None, 10)           11530       ['flatten_3[0][0]']
==================================================================================================
Total params: 913,362
Trainable params: 912,370
Non-trainable params: 992
__________________________________________________________________________________________________
Model: "my-model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_5 (InputLayer)           [(None, 180, 180, 3  0           []
                                )]
 conv2d_88 (Conv2D)             (None, 180, 180, 12  3584        ['input_5[0][0]']
                                8)
 re_lu_49 (ReLU)                (None, 180, 180, 12  0           ['conv2d_88[0][0]']
                                8)
 conv2d_89 (Conv2D)             (None, 180, 180, 12  147584      ['re_lu_49[0][0]']
                                8)
 re_lu_50 (ReLU)                (None, 180, 180, 12  0           ['conv2d_89[0][0]']
                                8)
 conv2d_90 (Conv2D)             (None, 180, 180, 12  147584      ['re_lu_50[0][0]']
                                8)
 batch_normalization_20 (BatchN  (None, 180, 180, 12  512        ['conv2d_90[0][0]']
 ormalization)                  8)
 conv2d_91 (Conv2D)             (None, 180, 180, 12  147584      ['batch_normalization_20[0][0]']
                                8)
 add_10 (Add)                   (None, 180, 180, 12  0           ['re_lu_50[0][0]',
                                8)                                'conv2d_91[0][0]']
 re_lu_51 (ReLU)                (None, 180, 180, 12  0           ['add_10[0][0]']
                                8)
 batch_normalization_21 (BatchN  (None, 180, 180, 12  512        ['re_lu_51[0][0]']
 ormalization)                  8)
 conv2d_92 (Conv2D)             (None, 90, 90, 128)  147584      ['batch_normalization_21[0][0]']
 conv2d_93 (Conv2D)             (None, 90, 90, 64)   73792       ['conv2d_92[0][0]']
 re_lu_52 (ReLU)                (None, 90, 90, 64)   0           ['conv2d_93[0][0]']
 conv2d_94 (Conv2D)             (None, 90, 90, 64)   36928       ['re_lu_52[0][0]']
 re_lu_53 (ReLU)                (None, 90, 90, 64)   0           ['conv2d_94[0][0]']
 conv2d_95 (Conv2D)             (None, 90, 90, 64)   36928       ['re_lu_53[0][0]']
 batch_normalization_22 (BatchN  (None, 90, 90, 64)  256         ['conv2d_95[0][0]']
 ormalization)
 conv2d_96 (Conv2D)             (None, 90, 90, 64)   36928       ['batch_normalization_22[0][0]']
 add_11 (Add)                   (None, 90, 90, 64)   0           ['re_lu_53[0][0]',
                                                                  'conv2d_96[0][0]']
 re_lu_54 (ReLU)                (None, 90, 90, 64)   0           ['add_11[0][0]']
 batch_normalization_23 (BatchN  (None, 90, 90, 64)  256         ['re_lu_54[0][0]']
 ormalization)
 conv2d_97 (Conv2D)             (None, 45, 45, 64)   36928       ['batch_normalization_23[0][0]']
 conv2d_98 (Conv2D)             (None, 45, 45, 32)   18464       ['conv2d_97[0][0]']
 re_lu_55 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_98[0][0]']
 conv2d_99 (Conv2D)             (None, 45, 45, 32)   9248        ['re_lu_55[0][0]']
 re_lu_56 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_99[0][0]']
 conv2d_100 (Conv2D)            (None, 45, 45, 32)   9248        ['re_lu_56[0][0]']
 re_lu_57 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_100[0][0]']
 conv2d_101 (Conv2D)            (None, 45, 45, 32)   9248        ['re_lu_57[0][0]']
 batch_normalization_24 (BatchN  (None, 45, 45, 32)  128         ['conv2d_101[0][0]']
 ormalization)
 conv2d_102 (Conv2D)            (None, 45, 45, 32)   9248        ['batch_normalization_24[0][0]']
 add_12 (Add)                   (None, 45, 45, 32)   0           ['re_lu_57[0][0]',
                                                                  'conv2d_102[0][0]']
 re_lu_58 (ReLU)                (None, 45, 45, 32)   0           ['add_12[0][0]']
 batch_normalization_25 (BatchN  (None, 45, 45, 32)  128         ['re_lu_58[0][0]']
 ormalization)
 conv2d_103 (Conv2D)            (None, 23, 23, 32)   9248        ['batch_normalization_25[0][0]']
 conv2d_104 (Conv2D)            (None, 23, 23, 16)   4624        ['conv2d_103[0][0]']
 re_lu_59 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_104[0][0]']
 conv2d_105 (Conv2D)            (None, 23, 23, 16)   2320        ['re_lu_59[0][0]']
 re_lu_60 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_105[0][0]']
 conv2d_106 (Conv2D)            (None, 23, 23, 16)   2320        ['re_lu_60[0][0]']
 re_lu_61 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_106[0][0]']
 conv2d_107 (Conv2D)            (None, 23, 23, 16)   2320        ['re_lu_61[0][0]']
 batch_normalization_26 (BatchN  (None, 23, 23, 16)  64          ['conv2d_107[0][0]']
 ormalization)
 conv2d_108 (Conv2D)            (None, 23, 23, 16)   2320        ['batch_normalization_26[0][0]']
 add_13 (Add)                   (None, 23, 23, 16)   0           ['re_lu_61[0][0]',
                                                                  'conv2d_108[0][0]']
 re_lu_62 (ReLU)                (None, 23, 23, 16)   0           ['add_13[0][0]']
 batch_normalization_27 (BatchN  (None, 23, 23, 16)  64          ['re_lu_62[0][0]']
 ormalization)
 conv2d_109 (Conv2D)            (None, 12, 12, 16)   2320        ['batch_normalization_27[0][0]']
 conv2d_110 (Conv2D)            (None, 12, 12, 8)    1160        ['conv2d_109[0][0]']
 re_lu_63 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_110[0][0]']
 conv2d_111 (Conv2D)            (None, 12, 12, 8)    584         ['re_lu_63[0][0]']
 re_lu_64 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_111[0][0]']
 conv2d_112 (Conv2D)            (None, 12, 12, 8)    584         ['re_lu_64[0][0]']
 re_lu_65 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_112[0][0]']
 conv2d_113 (Conv2D)            (None, 12, 12, 8)    584         ['re_lu_65[0][0]']
 batch_normalization_28 (BatchN  (None, 12, 12, 8)   32          ['conv2d_113[0][0]']
 ormalization)
 conv2d_114 (Conv2D)            (None, 12, 12, 8)    584         ['batch_normalization_28[0][0]']
 add_14 (Add)                   (None, 12, 12, 8)    0           ['re_lu_65[0][0]',
                                                                  'conv2d_114[0][0]']
 re_lu_66 (ReLU)                (None, 12, 12, 8)    0           ['add_14[0][0]']
 batch_normalization_29 (BatchN  (None, 12, 12, 8)   32          ['re_lu_66[0][0]']
 ormalization)
 flatten_4 (Flatten)            (None, 1152)         0           ['batch_normalization_29[0][0]']
 dense_4 (Dense)                (None, 10)           11530       ['flatten_4[0][0]']
==================================================================================================
Total params: 913,362
Trainable params: 912,370
Non-trainable params: 992
__________________________________________________________________________________________________
Epoch 1/4
/home/andrea/miniconda3/envs/tf-n-gpu/lib/python3.10/site-packages/keras/backend.py:5695: UserWarning: "`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?
  output, from_logits = _get_logits(
Epoch 1/4
Epoch 1/4
Epoch 1/4
Epoch 1/4
Epoch 1/4
Model: "my-model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_6 (InputLayer)           [(None, 180, 180, 3  0           []
                                )]
 conv2d_115 (Conv2D)            (None, 180, 180, 12  3584        ['input_6[0][0]']
                                8)
 re_lu_67 (ReLU)                (None, 180, 180, 12  0           ['conv2d_115[0][0]']
                                8)
 conv2d_116 (Conv2D)            (None, 180, 180, 12  147584      ['re_lu_67[0][0]']
                                8)
 re_lu_68 (ReLU)                (None, 180, 180, 12  0           ['conv2d_116[0][0]']
                                8)
 conv2d_117 (Conv2D)            (None, 180, 180, 12  147584      ['re_lu_68[0][0]']
                                8)
 batch_normalization_30 (BatchN  (None, 180, 180, 12  512        ['conv2d_117[0][0]']
 ormalization)                  8)
 conv2d_118 (Conv2D)            (None, 180, 180, 12  147584      ['batch_normalization_30[0][0]']
                                8)
 add_15 (Add)                   (None, 180, 180, 12  0           ['re_lu_68[0][0]',
                                8)                                'conv2d_118[0][0]']
 re_lu_69 (ReLU)                (None, 180, 180, 12  0           ['add_15[0][0]']
                                8)
 batch_normalization_31 (BatchN  (None, 180, 180, 12  512        ['re_lu_69[0][0]']
 ormalization)                  8)
 conv2d_119 (Conv2D)            (None, 90, 90, 128)  147584      ['batch_normalization_31[0][0]']
 conv2d_120 (Conv2D)            (None, 90, 90, 64)   73792       ['conv2d_119[0][0]']
 re_lu_70 (ReLU)                (None, 90, 90, 64)   0           ['conv2d_120[0][0]']
 conv2d_121 (Conv2D)            (None, 90, 90, 64)   36928       ['re_lu_70[0][0]']
 re_lu_71 (ReLU)                (None, 90, 90, 64)   0           ['conv2d_121[0][0]']
 conv2d_122 (Conv2D)            (None, 90, 90, 64)   36928       ['re_lu_71[0][0]']
 batch_normalization_32 (BatchN  (None, 90, 90, 64)  256         ['conv2d_122[0][0]']
 ormalization)
 conv2d_123 (Conv2D)            (None, 90, 90, 64)   36928       ['batch_normalization_32[0][0]']
 add_16 (Add)                   (None, 90, 90, 64)   0           ['re_lu_71[0][0]',
                                                                  'conv2d_123[0][0]']
 re_lu_72 (ReLU)                (None, 90, 90, 64)   0           ['add_16[0][0]']
 batch_normalization_33 (BatchN  (None, 90, 90, 64)  256         ['re_lu_72[0][0]']
 ormalization)
 conv2d_124 (Conv2D)            (None, 45, 45, 64)   36928       ['batch_normalization_33[0][0]']
 conv2d_125 (Conv2D)            (None, 45, 45, 32)   18464       ['conv2d_124[0][0]']
 re_lu_73 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_125[0][0]']
 conv2d_126 (Conv2D)            (None, 45, 45, 32)   9248        ['re_lu_73[0][0]']
 re_lu_74 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_126[0][0]']
 conv2d_127 (Conv2D)            (None, 45, 45, 32)   9248        ['re_lu_74[0][0]']
 re_lu_75 (ReLU)                (None, 45, 45, 32)   0           ['conv2d_127[0][0]']
 conv2d_128 (Conv2D)            (None, 45, 45, 32)   9248        ['re_lu_75[0][0]']
 batch_normalization_34 (BatchN  (None, 45, 45, 32)  128         ['conv2d_128[0][0]']
 ormalization)
 conv2d_129 (Conv2D)            (None, 45, 45, 32)   9248        ['batch_normalization_34[0][0]']
 add_17 (Add)                   (None, 45, 45, 32)   0           ['re_lu_75[0][0]',
                                                                  'conv2d_129[0][0]']
 re_lu_76 (ReLU)                (None, 45, 45, 32)   0           ['add_17[0][0]']
 batch_normalization_35 (BatchN  (None, 45, 45, 32)  128         ['re_lu_76[0][0]']
 ormalization)
 conv2d_130 (Conv2D)            (None, 23, 23, 32)   9248        ['batch_normalization_35[0][0]']
 conv2d_131 (Conv2D)            (None, 23, 23, 16)   4624        ['conv2d_130[0][0]']
 re_lu_77 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_131[0][0]']
 conv2d_132 (Conv2D)            (None, 23, 23, 16)   2320        ['re_lu_77[0][0]']
 re_lu_78 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_132[0][0]']
 conv2d_133 (Conv2D)            (None, 23, 23, 16)   2320        ['re_lu_78[0][0]']
 re_lu_79 (ReLU)                (None, 23, 23, 16)   0           ['conv2d_133[0][0]']
 conv2d_134 (Conv2D)            (None, 23, 23, 16)   2320        ['re_lu_79[0][0]']
 batch_normalization_36 (BatchN  (None, 23, 23, 16)  64          ['conv2d_134[0][0]']
 ormalization)
 conv2d_135 (Conv2D)            (None, 23, 23, 16)   2320        ['batch_normalization_36[0][0]']
 add_18 (Add)                   (None, 23, 23, 16)   0           ['re_lu_79[0][0]',
                                                                  'conv2d_135[0][0]']
 re_lu_80 (ReLU)                (None, 23, 23, 16)   0           ['add_18[0][0]']
 batch_normalization_37 (BatchN  (None, 23, 23, 16)  64          ['re_lu_80[0][0]']
 ormalization)
 conv2d_136 (Conv2D)            (None, 12, 12, 16)   2320        ['batch_normalization_37[0][0]']
 conv2d_137 (Conv2D)            (None, 12, 12, 8)    1160        ['conv2d_136[0][0]']
 re_lu_81 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_137[0][0]']
 conv2d_138 (Conv2D)            (None, 12, 12, 8)    584         ['re_lu_81[0][0]']
 re_lu_82 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_138[0][0]']
 conv2d_139 (Conv2D)            (None, 12, 12, 8)    584         ['re_lu_82[0][0]']
 re_lu_83 (ReLU)                (None, 12, 12, 8)    0           ['conv2d_139[0][0]']
 conv2d_140 (Conv2D)            (None, 12, 12, 8)    584         ['re_lu_83[0][0]']
 batch_normalization_38 (BatchN  (None, 12, 12, 8)   32          ['conv2d_140[0][0]']
 ormalization)
 conv2d_141 (Conv2D)            (None, 12, 12, 8)    584         ['batch_normalization_38[0][0]']
 add_19 (Add)                   (None, 12, 12, 8)    0           ['re_lu_83[0][0]',
                                                                  'conv2d_141[0][0]']
 re_lu_84 (ReLU)                (None, 12, 12, 8)    0           ['add_19[0][0]']
 batch_normalization_39 (BatchN  (None, 12, 12, 8)   32          ['re_lu_84[0][0]']
 ormalization)
 flatten_5 (Flatten)            (None, 1152)         0           ['batch_normalization_39[0][0]']
 dense_5 (Dense)                (None, 10)           11530       ['flatten_5[0][0]']
==================================================================================================
Total params: 913,362
Trainable params: 912,370
Non-trainable params: 992
__________________________________________________________________________________________________
2022-12-27 12:56:58.721489: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [5400]
	 [[{{node Placeholder/_4}}]]
2022-12-27 12:56:58.721667: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [5400]
	 [[{{node Placeholder/_4}}]]
Epoch 1/4
2022-12-27 12:56:59.161157: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [21600]
	 [[{{node Placeholder/_4}}]]
2022-12-27 12:56:59.161336: I tensorflow/core/common_runtime/executor.cc:1195] [/device:CPU:0] Executor start aborting: INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [21600]
	 [[{{node Placeholder/_4}}]]
  2/675 [..............................] - ETA: 2:45 - loss: 0.8756 - binary_crossentropy: 0.8756
  6/675 [..............................] - ETA: 2:22 - loss: 0.6955 - binary_crossentropy: 0.6955WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0764s vs `on_train_batch_end` time: 0.1132s). Check your callbacks.









 86/675 [==>...........................] - ETA: 1:57 - loss: 0.3228 - binary_crossentropy: 0.3228Epoch 1/4
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0732s vs `on_train_batch_end` time: 0.1123s). Check your callbacks.
  6/675 [..............................] - ETA: 2:19 - loss: 0.2950 - binary_crossentropy: 0.2950 - categorical_accuracy: 0.2344WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0732s vs `on_train_batch_end` time: 0.1123s). Check your callbacks.



























332/675 [=============>................] - ETA: 1:07 - loss: 0.2618 - binary_crossentropy: 0.2618 - categorical_accuracy: 0.3534
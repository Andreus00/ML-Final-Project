{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project by Andrea Sanchietti\n",
    "\n",
    "This is the second homework for the machine learning course.\n",
    "\n",
    "It requires to design a model for classification of images from a dataset made of at least 10 diffrerent classes.\n",
    "\n",
    "The dataset that i decided to use is the EuroSAT Dataset: a collection of satellitar images based on Sentinel-2 satellite images covering 13 spectral bands and consisting out of 10 classes with in total 27,000 labeled and geo-referenced images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import Callback\n",
    "from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "import config\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if False:\n",
    "    import wandb\n",
    "    from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "    run = wandb.init(project=\"ML-final-project\", entity=\"andr3us\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is reading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birds\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  config.training_dir,\n",
    "  seed=123,\n",
    "  image_size=(config.img_height, config.img_width),\n",
    "  batch_size=config.batch_size,\n",
    "  shuffle=True)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  config.valid_dir,\n",
    "  seed=123,\n",
    "  image_size=(config.img_height, config.img_width),\n",
    "  batch_size=config.batch_size,\n",
    "  shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EuroSat\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  config.training_dir_eurosat,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(config.img_height, config.img_width),\n",
    "  batch_size=config.batch_size,\n",
    "  shuffle=True)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  config.training_dir_eurosat,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(config.img_height, config.img_width),\n",
    "  batch_size=config.batch_size,\n",
    "  shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "    if i >= 8:\n",
    "      print(images[i].shape)\n",
    "      print(labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data argumentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomContrast(factor=0.1),\n",
    "  tf.keras.layers.RandomZoom(height_factor=0.1, width_factor=0.1)\n",
    "])\n",
    "\n",
    "train_ds.map(lambda x, y: (data_augmentation(x), y, config.classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), tf.one_hot(y, config.classes)))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), tf.one_hot(y, config.classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for autoencoder training\n",
    "# padding_layer = tf.keras.layers.ZeroPadding2D(38)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (x, x))\n",
    "val_ds = val_ds.map(lambda x, y: (x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resblock(x, filters, kernelsize):\n",
    "    fx = tf.keras.layers.Conv2D(filters, kernelsize, activation='relu', padding='same')(x)\n",
    "    fx = tf.keras.layers.BatchNormalization()(fx)\n",
    "    fx = tf.keras.layers.Conv2D(filters, kernelsize, padding='same')(fx)\n",
    "    out = tf.keras.layers.Add()([x,fx])\n",
    "    out = tf.keras.layers.ReLU()(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def convblock2d(x, filters, kernelsize: int, num_convs: int, activation=\"relu\", padding=\"same\"):\n",
    "    if num_convs <= 0:\n",
    "        return x\n",
    "    out = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernelsize, padding=padding)(x)\n",
    "    for i in range(num_convs - 1):\n",
    "        out = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernelsize, activation=\"relu\", padding=padding)(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def convblock2dregularized(x, filters, kernelsize: int, num_convs: int, activation=\"relu\", padding=\"same\"):\n",
    "    if num_convs <= 0:\n",
    "        return x\n",
    "    out = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernelsize, padding=padding, kernel_regularizer=\"l2\")(x)\n",
    "    out = tf.keras.layers.Dropout(0.2)(out)\n",
    "    for i in range(num_convs - 1):\n",
    "        out = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernelsize, activation=\"relu\", padding=padding, kernel_regularizer=\"l2\")(out)\n",
    "        out = tf.keras.layers.Dropout(0.2)(out)\n",
    "    return out\n",
    "\n",
    "def convblock2dregularized2(x, filters, kernelsize: int, num_convs: int, activation=\"relu\", padding=\"same\"):\n",
    "    if num_convs <= 0:\n",
    "        return x\n",
    "    out = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernelsize, padding=padding, kernel_regularizer=\"l2\")(x)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    for i in range(num_convs - 1):\n",
    "        out = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernelsize, activation=activation, padding=padding, kernel_regularizer=\"l2\")(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1\n",
    "def encoder(inputs):\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    hidden_layer = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(hidden_layer) # 180 -> 90\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\")(hidden_layer)\n",
    "    bottleneck = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(hidden_layer) # 90 -> 45    \n",
    "    return bottleneck\n",
    "\n",
    "\n",
    "def decoder(bottleneck):\n",
    "    # input 16\n",
    "    hidden_layer = tf.keras.layers.Conv2D(name='Decoder', filters=16, kernel_size=3, padding=\"same\", activation=\"relu\")(bottleneck)\n",
    "    hidden_layer = tf.keras.layers.UpSampling2D((2, 2))(hidden_layer) # 45 -> 90\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\")(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.UpSampling2D((2, 2))(hidden_layer) # 90 -> 180\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")(hidden_layer)\n",
    "    output = tf.keras.layers.Conv2D(name=\"output\", filters=3, kernel_size=5, padding=\"same\", activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def autoencoder_1():\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    enc = encoder(inputs)\n",
    "    outputs = decoder(enc)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"ConvAutoencoder_v1\"), 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2\n",
    "def decoder(bottleneck):\n",
    "    x = tf.keras.layers.Convolution2D(8, 7, activation='relu', padding='same')(bottleneck)\n",
    "    x = tf.keras.layers.UpSampling2D((2, 2))(x) # 45 -> 90\n",
    "    x = tf.keras.layers.Convolution2D(16, 7, activation='relu', padding='same')(x) \n",
    "\n",
    "    x = tf.keras.layers.UpSampling2D((2, 2))(x) # 90 -> 180\n",
    "    decoded = tf.keras.layers.Convolution2D(3, 5, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    return decoded\n",
    "\n",
    "def encoder(inputs):\n",
    "    x = tf.keras.layers.Convolution2D(16, 7, activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x) # 180 -> 90\n",
    "    x = tf.keras.layers.Convolution2D(8, 7, activation='relu', padding='same')(x)\n",
    "    bottleneck = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x) # 90 -> 45 \n",
    "\n",
    "    return bottleneck\n",
    "\n",
    "def autoencoder_2():\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    enc = encoder(inputs)\n",
    "    outputs = decoder(enc)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"ConvAutoencoder_v2\"), 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet():\n",
    "    return tf.keras.applications.resnet50.ResNet50(input_shape=config.input_shape, classes=config.classes, classifier_activation=\"softmax\", weights=None), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception():\n",
    "    # input_tensor = tf.keras.Input(shape=(config.img_width, config.img_height, 3))\n",
    "    incep = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(config.img_width, config.img_height, 3),\n",
    "    pooling=None,\n",
    "    classes=config.classes,\n",
    "    classifier_activation=\"softmax\",\n",
    "    )\n",
    "    for layer in incep.layers:\n",
    "        layer.trainable = False\n",
    "    incep.summary()\n",
    "\n",
    "    last_layer = incep.get_layer(\"mixed10\")\n",
    "    print(\"Last layer:\", last_layer)\n",
    "\n",
    "    last_layer = last_layer.output\n",
    "\n",
    "    # build a custrom top\n",
    "    x = tf.keras.layers.Flatten()(last_layer)\n",
    "\n",
    "    x = tf.keras.layers.Dense(2048, activation=\"relu\")(x)\n",
    "\n",
    "    # Dropout regularization to prevent overfitting\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(config.classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs=incep.input, outputs=output_layer, name=\"Inception\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_l_6():\n",
    "\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    hidden_layer = convblock2dregularized2(inputs, 16, 5, 2)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized2(hidden_layer, 32, 5, 2)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized2(hidden_layer, 64, 5, 3)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized2(hidden_layer, 128, 3, 3)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized2(hidden_layer, 256, 3, 3)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Flatten()(hidden_layer)\n",
    "    output_layer = tf.keras.layers.Dense(config.classes, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=output_layer, name=\"ConvResNet_v2\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_l_5():\n",
    "\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    hidden_layer = convblock2dregularized2(inputs, 32, 3, 2)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized2(hidden_layer, 64, 3, 2)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized2(hidden_layer, 128, 3, 3)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized2(hidden_layer, 256, 3, 3)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized2(hidden_layer, 512, 3, 3)\n",
    "    hidden_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = tf.keras.layers.Flatten()(hidden_layer)\n",
    "    output_layer = tf.keras.layers.Dense(config.classes, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=output_layer, name=\"ConvResNet_v2\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_l_4():\n",
    "\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    hidden_layer = convblock2dregularized(inputs, 64, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 64, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized(hidden_layer, 128, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 128, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized(hidden_layer, 256, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 256, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized(hidden_layer, 512, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 512, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2dregularized(hidden_layer, 1024, 3, 3)\n",
    "    hidden_layer = resblock(hidden_layer, 1024, 3)\n",
    "    hidden_layer = tf.keras.layers.Flatten()(hidden_layer)\n",
    "    output_layer = tf.keras.layers.Dense(config.classes, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=output_layer, name=\"ConvResNet_v2\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_l_3(): # Same as model 2\n",
    "\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    hidden_layer = convblock2d(inputs, 16, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 16, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 32, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 32, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 64, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 64, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 128, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 128, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 256, 3, 3)\n",
    "    hidden_layer = resblock(hidden_layer, 256, 3)\n",
    "    hidden_layer = tf.keras.layers.Flatten()(hidden_layer)\n",
    "    output_layer = tf.keras.layers.Dense(config.classes, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=output_layer, name=\"ConvResNet_v2\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_l_2():\n",
    "\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    hidden_layer = convblock2d(inputs, 64, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 64, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 128, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 128, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=126, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 256, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 256, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 512, 3, 2)\n",
    "    hidden_layer = resblock(hidden_layer, 512, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 1024, 3, 3)\n",
    "    hidden_layer = resblock(hidden_layer, 1024, 3)\n",
    "    hidden_layer = tf.keras.layers.Flatten()(hidden_layer)\n",
    "    output_layer = tf.keras.layers.Dense(config.classes, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=output_layer, name=\"ConvResNet_v2\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_l_1():\n",
    "    filt = 32\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    hidden_layer = convblock2d(inputs, filt, 3, 3)\n",
    "    hidden_layer = resblock(hidden_layer, filt, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=filt, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, filt * 2, 3, 3)\n",
    "    hidden_layer = resblock(hidden_layer, filt * 2, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=filt * 2, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, filt * 4, 3, 3)\n",
    "    hidden_layer = resblock(hidden_layer, filt * 4, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=filt * 4, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, filt * 8, 3, 3)\n",
    "    hidden_layer = resblock(hidden_layer, filt * 8, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=filt * 8, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, filt * 16, 3, 3)\n",
    "    hidden_layer = resblock(hidden_layer, filt * 16, 3)\n",
    "    hidden_layer = tf.keras.layers.Flatten()(hidden_layer)\n",
    "    output_layer = tf.keras.layers.Dense(config.classes, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=output_layer, name=\"ConvResNet_v1\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_0():\n",
    "\n",
    "    inputs = tf.keras.Input(shape=config.input_shape)\n",
    "    hidden_layer = convblock2d(inputs, 64, 3, 2)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 126, 3, 2)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=126, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 256, 3, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 512, 3, 3)\n",
    "    hidden_layer = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\", strides=2)(hidden_layer)\n",
    "    hidden_layer = convblock2d(hidden_layer, 1024, 3, 3)\n",
    "    hidden_layer = tf.keras.layers.Flatten()(hidden_layer)\n",
    "    output_layer = tf.keras.layers.Dense(config.classes, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=output_layer, name=\"FirstNet\"), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, mode = autoencoder_1()\n",
    "print(mode)\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model,to_file=\"model.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU') # True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for autoencoders\n",
    "\n",
    "class PredictOne(Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs= None) -> None:\n",
    "        \"\"\"Called at the end of an epoch.\"\"\"\n",
    "        for X, y in train_ds:    \n",
    "            y_pred = self.model.predict(X)\n",
    "\n",
    "            for pred, true in zip(y_pred, y):\n",
    "                print(pred.shape)\n",
    "                print(true.shape)\n",
    "                fig, ax = plt.subplots(1, 2)\n",
    "                ax[0].imshow(pred)\n",
    "                ax[1].imshow(true)\n",
    "                plt.show()\n",
    "                print(true[100, 100])\n",
    "                print(pred[100, 100])\n",
    "                break\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 0:\n",
    "  \n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(momentum=0.9, learning_rate=1e-4), # todo\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.CategoricalCrossentropy(), tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=40,\n",
    "    batch_size=config.batch_size,\n",
    "    callbacks=[WandbMetricsLogger(log_freq=\"batch\"),\n",
    "    WandbModelCheckpoint(\"model\", save_best_only=True)]\n",
    "  )\n",
    "elif mode == 1:\n",
    "\n",
    "  # Autoencoder\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(momentum=0.9, learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "  \n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=200,\n",
    "    batch_size=config.batch_size,\n",
    "    callbacks=[WandbMetricsLogger(log_freq=\"batch\"),\n",
    "    WandbModelCheckpoint(\"models_autoencoder\", save_best_only=True), \n",
    "    PredictOne()]\n",
    "  )\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a checkpoint model from wandb\n",
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('andr3us/ML-final-project/run_3bn4rasz_model:v17', type='model')\n",
    "artifact_dir = artifact.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = tf.keras.models.load_model(artifact_dir)\n",
    "model.compile(metrics=[tf.keras.metrics.CategoricalCrossentropy(), tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.Precision(top_k=1), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(val_ds, batch_size=128)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images of autoencoder\n",
    "\n",
    "for X, y in train_ds:    \n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    for pred, true in zip(y_pred, y):\n",
    "        print(pred.shape)\n",
    "        print(true.shape)\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(pred)\n",
    "        ax[1].imshow(true)\n",
    "        plt.show()\n",
    "        print(true[100, 100])\n",
    "        print(pred[100, 100])\n",
    "        break\n",
    "    break\n",
    "# test /media/andrea/NVMe/Dataset/Eurosat/2750/Residential/Residential_1721.jpg\n",
    "\n",
    "\n",
    "# layer_name = 'relu_conv2'\n",
    "# model2= Model(inputs=model1.input, outputs=model1.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "for X, y in val_ds:\n",
    "    p = model.predict(X)\n",
    "    y_pred += [_ for _ in tf.argmax(p, axis=1)]\n",
    "    y_true += [_ for _ in tf.argmax(y, axis=1)]\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_true = np.asarray(y_true)\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(tf.argmax(y_pred_one_hot[i]), y_true[i], \"prediction: \", y_pred_one_hot[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(300, 300)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true, y_pred, cmap=\"PuBu\", ax = ax)\n",
    "fig.savefig(fname=\"BigMatrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classification with encoder\n",
    "# remember to reload dataset and normalize it without using the part that removes labels\n",
    "\n",
    "inp = model.input\n",
    "\n",
    "bottleneck = model.layers[5].output # take the bottleneck from autoencoder 1\n",
    "\n",
    "enc = tf.keras.Model(inp, bottleneck)\n",
    "enc.trainable = False\n",
    "enc.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the output SVM\n",
    "\n",
    "hidden_l = tf.keras.layers.Flatten()(bottleneck)\n",
    "hidden_l = tf.keras.layers.Dense(64, activation=\"relu\")(hidden_l)\n",
    "out = tf.keras.layers.Dense(10, activation=\"sigmoid\")(hidden_l)\n",
    "\n",
    "classifier = tf.keras.Model(inp, out)\n",
    "\n",
    "classifier.compile(loss='squared_hinge',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier.fit(train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    batch_size=config.batch_size,\n",
    "    callbacks=[WandbMetricsLogger(log_freq=\"batch\"),\n",
    "    WandbModelCheckpoint(\"model\", save_best_only=True)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-n-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c6cbd1756a1e8ee71006b67351214a6d16acb4a1ac2cbf5e576b0987d4bcb65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
